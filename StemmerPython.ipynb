{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuCBzy3xzU2mnO1boa8O6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FAYASISMAEL/AI-ML-Visualization-Files/blob/main/StemmerPython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEtv9lpnDgBD",
        "outputId": "63ba1d85-821f-4232-8432-70600fb4b9ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import corpus\n",
        "corpus =  'Two popular text normalization techniques in the field of Natural Language Processing (NLP), the application of computational techniques to analyze and synthesize natural language and speech, are stemming and lemmatization. Researchers have studied these techniques for years; NLP practitioners typically use them to prepare words, text, and documents for further processing in a number of tasks. '"
      ],
      "metadata": {
        "id": "tca18jlzDiT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = corpus.split()\n",
        "splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlvuhwtEDl9b",
        "outputId": "9d1f7ead-06c1-414a-9c55-05832bcf1998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Two',\n",
              " 'popular',\n",
              " 'text',\n",
              " 'normalization',\n",
              " 'techniques',\n",
              " 'in',\n",
              " 'the',\n",
              " 'field',\n",
              " 'of',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " '(NLP),',\n",
              " 'the',\n",
              " 'application',\n",
              " 'of',\n",
              " 'computational',\n",
              " 'techniques',\n",
              " 'to',\n",
              " 'analyze',\n",
              " 'and',\n",
              " 'synthesize',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'and',\n",
              " 'speech,',\n",
              " 'are',\n",
              " 'stemming',\n",
              " 'and',\n",
              " 'lemmatization.',\n",
              " 'Researchers',\n",
              " 'have',\n",
              " 'studied',\n",
              " 'these',\n",
              " 'techniques',\n",
              " 'for',\n",
              " 'years;',\n",
              " 'NLP',\n",
              " 'practitioners',\n",
              " 'typically',\n",
              " 'use',\n",
              " 'them',\n",
              " 'to',\n",
              " 'prepare',\n",
              " 'words,',\n",
              " 'text,',\n",
              " 'and',\n",
              " 'documents',\n",
              " 'for',\n",
              " 'further',\n",
              " 'processing',\n",
              " 'in',\n",
              " 'a',\n",
              " 'number',\n",
              " 'of',\n",
              " 'tasks.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "splits = para.split()\n",
        "stemmed_sentence = [ps.stem(word) for word in splits]\n",
        "\n",
        "print(stemmed_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV23zeh0Duoh",
        "outputId": "95020e97-fb7a-4cdc-f57d-5828ea50dd56"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['two', 'popular', 'text', 'normal', 'techniqu', 'in', 'the', 'field', 'of', 'natur', 'languag', 'process', '(nlp),', 'the', 'applic', 'of', 'comput', 'techniqu', 'to', 'analyz', 'and', 'synthes', 'natur', 'languag', 'and', 'speech,', 'are', 'stem', 'and', 'lemmatization.', 'research', 'have', 'studi', 'these', 'techniqu', 'for', 'years;', 'nlp', 'practition', 'typic', 'use', 'them', 'to', 'prepar', 'words,', 'text,', 'and', 'document', 'for', 'further', 'process', 'in', 'a', 'number', 'of', 'tasks.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download ('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('average_perception_tagger')"
      ],
      "metadata": {
        "id": "QLmMipKrIvNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe9ab16-bd28-44f7-d166-efaecfb41fec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Error loading average_perception_tagger: Package\n",
            "[nltk_data]     'average_perception_tagger' not found in index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "Lemmatizer = WordNetLemmatizer()\n",
        "Lemmatizer_word = [Lemmatizer.lemmatize(word) for word in splits]\n",
        "print(Lemmatizer_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K67YLrTaJbDJ",
        "outputId": "8189b8bc-1fe6-41d1-c3b7-b1f9a4a55f9f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Two', 'popular', 'text', 'normalization', 'technique', 'in', 'the', 'field', 'of', 'Natural', 'Language', 'Processing', '(NLP),', 'the', 'application', 'of', 'computational', 'technique', 'to', 'analyze', 'and', 'synthesize', 'natural', 'language', 'and', 'speech,', 'are', 'stemming', 'and', 'lemmatization.', 'Researchers', 'have', 'studied', 'these', 'technique', 'for', 'years;', 'NLP', 'practitioner', 'typically', 'use', 'them', 'to', 'prepare', 'words,', 'text,', 'and', 'document', 'for', 'further', 'processing', 'in', 'a', 'number', 'of', 'tasks.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RegexStemmer"
      ],
      "metadata": {
        "id": "2G4LVkUvKTkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "\n",
        "ps = RegexpStemmer('ing$, ed$, able$, s$')\n",
        "\n",
        "# splits = corpus.split()      # already tokenized word\n",
        "stemmed_sentence = [ps.stem(word) for word in splits]\n",
        "print(stemmed_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qhC-gJyKDH7",
        "outputId": "d6b3532a-ce20-4ab4-e762-c29484b9170e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Two', 'popular', 'text', 'normalization', 'techniques', 'in', 'the', 'field', 'of', 'Natural', 'Language', 'Processing', '(NLP),', 'the', 'application', 'of', 'computational', 'techniques', 'to', 'analyze', 'and', 'synthesize', 'natural', 'language', 'and', 'speech,', 'are', 'stemming', 'and', 'lemmatization.', 'Researchers', 'have', 'studied', 'these', 'techniques', 'for', 'years;', 'NLP', 'practitioners', 'typically', 'use', 'them', 'to', 'prepare', 'words,', 'text,', 'and', 'documents', 'for', 'further', 'processing', 'in', 'a', 'number', 'of', 'tasks.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ChJQP_c1K8Cv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}